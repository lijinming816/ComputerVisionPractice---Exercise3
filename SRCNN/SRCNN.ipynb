{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462c7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\n",
    "    Examples::\n",
    "        >>> # Initialize a meter to record loss\n",
    "        >>> losses = AverageMeter()\n",
    "        >>> # Update meter after every minibatch update\n",
    "        >>> losses.update(loss_value, batch_size)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "\n",
    "def convert_rgb_to_ycbcr(img):\n",
    "    if type(img) == np.ndarray:\n",
    "        y = 16. + (64.738 * img[:, :, 0] + 129.057 * img[:, :, 1] + 25.064 * img[:, :, 2]) / 256.\n",
    "        cb = 128. + (-37.945 * img[:, :, 0] - 74.494 * img[:, :, 1] + 112.439 * img[:, :, 2]) / 256.\n",
    "        cr = 128. + (112.439 * img[:, :, 0] - 94.154 * img[:, :, 1] - 18.285 * img[:, :, 2]) / 256.\n",
    "        return np.array([y, cb, cr]).transpose([1, 2, 0])\n",
    "    elif type(img) == torch.Tensor:\n",
    "        if len(img.shape) == 4:\n",
    "            img = img.squeeze(0)\n",
    "        y = 16. + (64.738 * img[0, :, :] + 129.057 * img[1, :, :] + 25.064 * img[2, :, :]) / 256.\n",
    "        cb = 128. + (-37.945 * img[0, :, :] - 74.494 * img[1, :, :] + 112.439 * img[2, :, :]) / 256.\n",
    "        cr = 128. + (112.439 * img[0, :, :] - 94.154 * img[1, :, :] - 18.285 * img[2, :, :]) / 256.\n",
    "        return torch.cat([y, cb, cr], 0).permute(1, 2, 0)\n",
    "    else:\n",
    "        raise Exception('Unknown Type', type(img))\n",
    "\n",
    "def convert_ycbcr_to_rgb(img):\n",
    "    if type(img) == np.ndarray:\n",
    "        r = 298.082 * img[:, :, 0] / 256. + 408.583 * img[:, :, 2] / 256. - 222.921\n",
    "        g = 298.082 * img[:, :, 0] / 256. - 100.291 * img[:, :, 1] / 256. - 208.120 * img[:, :, 2] / 256. + 135.576\n",
    "        b = 298.082 * img[:, :, 0] / 256. + 516.412 * img[:, :, 1] / 256. - 276.836\n",
    "        return np.array([r, g, b]).transpose([1, 2, 0])\n",
    "    elif type(img) == torch.Tensor:\n",
    "        if len(img.shape) == 4:\n",
    "            img = img.squeeze(0)\n",
    "        r = 298.082 * img[0, :, :] / 256. + 408.583 * img[2, :, :] / 256. - 222.921\n",
    "        g = 298.082 * img[0, :, :] / 256. - 100.291 * img[1, :, :] / 256. - 208.120 * img[2, :, :] / 256. + 135.576\n",
    "        b = 298.082 * img[0, :, :] / 256. + 516.412 * img[1, :, :] / 256. - 276.836\n",
    "        return torch.cat([r, g, b], 0).permute(1, 2, 0)\n",
    "    else:\n",
    "        raise Exception('Unknown Type', type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6c6a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import h5py\n",
    "import PIL.Image as pImg\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def rgb2gray(img):\n",
    "    return 16. + (64.738 * img[:, :, 0] + 129.057 * img[:, :, 1] + 25.064 * img[:, :, 2]) / 256.\n",
    "\n",
    "\n",
    "\n",
    "# imgPath为图像路径；h5Path为存储路径；scale为放大倍数\n",
    "# pSize为patch尺寸； pStride为步长\n",
    "def setTrianData(imgPath, h5Path, scale=3, pSize=33, pStride=14):\n",
    "    h5_file = h5py.File(h5Path, 'w')\n",
    "    lrPatches, hrPatches = [], []  # 用于存储低分辨率和高分辨率的patch\n",
    "    for p in sorted(glob.glob(f'{imgPath}/*')):\n",
    "        hr = pImg.open(p).convert('RGB')\n",
    "        lrWidth, lrHeight = hr.width // scale, hr.height // scale\n",
    "        # width, height为可被scale整除的训练数据尺寸\n",
    "        width, height = lrWidth * scale, lrHeight * scale\n",
    "        hr = hr.resize((width, height), resample=pImg.BICUBIC)\n",
    "        lr = hr.resize((lrWidth, lrHeight), resample=pImg.BICUBIC)\n",
    "        lr = lr.resize((width, height), resample=pImg.BICUBIC)\n",
    "        hr = np.array(hr).astype(np.float32)\n",
    "        lr = np.array(lr).astype(np.float32)\n",
    "        hr = rgb2gray(hr)\n",
    "        lr = rgb2gray(lr)\n",
    "        # 将数据分割\n",
    "        for i in range(0, height - pSize + 1, pStride):\n",
    "            for j in range(0, width - pSize + 1, pStride):\n",
    "                lrPatches.append(lr[i:i + pSize, j:j + pSize])\n",
    "                hrPatches.append(hr[i:i + pSize, j:j + pSize])\n",
    "    h5_file.create_dataset('lr', data=np.array(lrPatches))\n",
    "    h5_file.create_dataset('hr', data=np.array(hrPatches))\n",
    "    h5_file.close()\n",
    "\n",
    "\n",
    "class DataSet(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.h5_file = h5_file\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return np.expand_dims(f['lr'][idx] / 255., 0), np.expand_dims(f['hr'][idx] / 255., 0)\n",
    "\n",
    "    def __len__(self):\n",
    "        with h5py.File(self.h5_file, 'r') as f:\n",
    "            return len(f['lr'])\n",
    "\n",
    "\n",
    "# 生成数据集\n",
    "# trainIamgePath = 'T91'\n",
    "# testTamgePath = 'Set5'\n",
    "# trainSavePath = 'T91.h5'\n",
    "# testSavePath = 'Set5.h5'\n",
    "\n",
    "# setTrianData(trainIamgePath, trainSavePath)\n",
    "# setTrianData(testTamgePath, testSavePath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe98d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from data_process import DataSet\n",
    "import utils\n",
    "\n",
    "# models.py\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, nChannel=1):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(nChannel, 64,\n",
    "                               kernel_size=9, padding=9 // 2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(32, nChannel,\n",
    "                               kernel_size=5, padding=5 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "cudnn.benchmark = True\n",
    "# 设置训练设备 是CPU还是cuda\n",
    "# device = torch.device(\n",
    "#   'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "outPath = \"outputs\"\n",
    "scale = 3\n",
    "bSize = 16\n",
    "nEpoch = 400\n",
    "nWorker = 8  # 线程数\n",
    "seed = 42  # 随机数种子\n",
    "\n",
    "# 模型和设备\n",
    "lr = 1e-4  # 学习率\n",
    "torch.manual_seed(seed)  # 设置随机数种子\n",
    "model = SRCNN().to(device)  # 将模型载入设备\n",
    "criterion = nn.MSELoss()  # 设置损失函数\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.conv1.parameters()},\n",
    "    {'params': model.conv2.parameters()},\n",
    "    {'params': model.conv3.parameters(), 'lr': lr * 0.1}\n",
    "], lr=lr)\n",
    "\n",
    "trainFile = \"T91.h5\"\n",
    "evalFile = \"Set5.h5\"\n",
    "\n",
    "# 装载训练数据\n",
    "trainData = DataSet(trainFile)\n",
    "trainLoader = DataLoader(dataset=trainData,\n",
    "                         batch_size=bSize,\n",
    "                         shuffle=True)  # 表示打乱样本)\n",
    "\n",
    "# 装载预测数据\n",
    "evalDatas = DataSet(evalFile)\n",
    "evalLoader = DataLoader(dataset=evalDatas, batch_size=1)\n",
    "\n",
    "\n",
    "def initPSNR():\n",
    "    return {'avg': 0, 'sum': 0, 'count': 0}\n",
    "\n",
    "\n",
    "def updatePSNR(psnr, val, n=1):\n",
    "    s = psnr['sum'] + val * n\n",
    "    c = psnr['count'] + n\n",
    "    return {'avg': s / c, 'sum': s, 'count': c}\n",
    "\n",
    "\n",
    "bestWeights = copy.deepcopy(model.state_dict())  # 最佳模型\n",
    "bestEpoch = 0  # 最佳训练结果\n",
    "bestPSNR = 0.0  # 最佳psnr\n",
    "\n",
    "# 训练主循环\n",
    "for epoch in range(nEpoch):\n",
    "    print('times:'+str(epoch))\n",
    "    model.train()\n",
    "    epochLosses = initPSNR()\n",
    "\n",
    "    # 训练\n",
    "    for data in trainLoader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        preds = model(inputs)\n",
    "        loss = criterion(preds, labels)\n",
    "        epochLosses = updatePSNR(epochLosses, loss.item(), len(inputs))\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 根据梯度更新网络参数\n",
    "\n",
    "    print(str(epochLosses['avg']))\n",
    "    torch.save(model.state_dict(), os.path.join(outPath, f'epoch_{epoch}.pth'))\n",
    "\n",
    "    # 测试\n",
    "    model.eval()  # 取消dropout\n",
    "    psnr = utils.AverageMeter()\n",
    "    for data in evalLoader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 令reqires_grad自动设为False，关闭自动求导\n",
    "        # clamp将inputs归一化为0到1区间\n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs).clamp(0.0, 1.0)\n",
    "\n",
    "        tmp_psnr = 10. * torch.log10(1. / torch.mean((preds - labels) ** 2))\n",
    "        psnr.update(tmp_psnr, len(inputs))\n",
    "\n",
    "    print(f'eval psnr: {psnr.avg:.2f}')\n",
    "\n",
    "    if psnr.avg > bestPSNR:\n",
    "        bestEpoch = epoch\n",
    "        bestPSNR = psnr.avg\n",
    "        bestWeights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "print(f'best epoch: {bestEpoch}, psnr: {bestPSNR:.2f}')\n",
    "torch.save(bestWeights, os.path.join(outPath, 'best_'+str(bestEpoch)+'_'+str(bestPSNR)+'.pth'))\n",
    "\n",
    "\n",
    "# test\n",
    "\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import PIL.Image as pil_image\n",
    "from data_process import DataSet\n",
    "from utils import convert_rgb_to_ycbcr, convert_ycbcr_to_rgb\n",
    "\n",
    "\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, nChannel=1):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(nChannel, 64,\n",
    "                               kernel_size=9, padding=9 // 2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1)\n",
    "        self.conv3 = nn.Conv2d(32, nChannel,\n",
    "                               kernel_size=5, padding=5 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--image-file', default='Set5/woman.png', type=str)\n",
    "\n",
    "parser.add_argument('--scale', type=int, default=3)\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = torch.device('cpu')\n",
    "model = SRCNN()\n",
    "model.load_state_dict(torch.load('outputs/best_83_36.28.pth'))\n",
    "model.eval()\n",
    "\n",
    "image = pil_image.open(args.image_file).convert('RGB')   # 将图片转为RGB类型\n",
    "image_width = (image.width // 3) * 3\n",
    "image_height = (image.height // 3) * 3\n",
    "image = image.resize((image_width, image_height), resample=pil_image.BICUBIC)\n",
    "image = image.resize((image.width // 3, image.height // 3), resample=pil_image.BICUBIC)\n",
    "image = image.resize((image.width * 3, image.height * 3), resample=pil_image.BICUBIC)\n",
    "image.save(args.image_file.replace('.', '_bicubic_x{}.'.format(3)))\n",
    "# 将图像转化为数组类型，同时图像转为ycbcr类型\n",
    "image = np.array(image).astype(np.float32)\n",
    "ycbcr = convert_rgb_to_ycbcr(image)\n",
    "# 得到 ycbcr中的 y 通道\n",
    "y = ycbcr[..., 0]\n",
    "y /= 255.  # 归一化处理\n",
    "y = torch.from_numpy(y).to(device)  # 把数组转换成张量，且二者共享内存，对张量进行修改比如重新赋值，那么原始数组也会相应发生改变，并且将参数放到device上\n",
    "y = y.unsqueeze(0).unsqueeze(0)  # 增加两个维度\n",
    "# 令reqires_grad自动设为False，关闭自动求导\n",
    "# clamp将inputs归一化为0到1区间\n",
    "with torch.no_grad():\n",
    "    preds = model(y).clamp(0.0, 1.0)\n",
    "\n",
    "# 1.mul函数类似矩阵.*，即每个元素×255\n",
    "# 2. *.cpu（）.numpy（） 将数据的处理设备从其他设备（如gpu拿到cpu上），不会改变变量类型，转换后仍然是Tensor变量，同时将Tensor转化为ndarray\n",
    "# 3. *.squeeze(0).squeeze(0)数据的维度进行压缩\n",
    "preds = preds.mul(255.0).cpu().numpy().squeeze(0).squeeze(0)  # 得到的是经过模型处理，取值在[0,255]的y通道图像\n",
    "\n",
    "# 将img的数据格式由（channels,imagesize,imagesize）转化为（imagesize,imagesize,channels）,进行格式的转换后方可进行显示。\n",
    "output = np.array([preds, ycbcr[..., 1], ycbcr[..., 2]]).transpose([1, 2, 0])\n",
    "\n",
    "output = np.clip(convert_ycbcr_to_rgb(output), 0.0, 255.0).astype(\n",
    "    np.uint8)  # 将图像格式从ycbcr转为rgb，限制取值范围[0,255]，同时矩阵元素类型为uint8类型\n",
    "output = pil_image.fromarray(output)  # array转换成image，即将矩阵转为图像\n",
    "output.save(args.image_file.replace('.', '_srcnn_x{}.'.format(args.scale)))  # 对图像进行保存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
